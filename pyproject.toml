[project]
name = "simba-core"
version = "0.5.0"
description = "Customer Service Assistant - AI-powered support that answers fast and accurately"
authors = [{name = "GitHamza0206", email = "zeroualihamza0206@gmail.com"}]
readme = "README.md"
license = {text = "Apache-2.0"}
requires-python = ">=3.11,<3.13"
keywords = ["customer-service", "ai", "langchain", "rag", "chatbot"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: Apache Software License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
]

dependencies = [
    # Web framework
    "fastapi>=0.115.0",
    "uvicorn[standard]>=0.34.0",
    "python-multipart>=0.0.20",
    # LangChain ecosystem (latest)
    "langchain>=0.3.14",
    "langchain-core>=0.3.29",
    "langchain-community>=0.3.14",
    "langchain-openai>=0.3.0",
    "langgraph>=0.2.60",
    "langgraph-checkpoint-postgres>=2.0.0",
    "psycopg[binary,pool]>=3.2.0", # Required for async postgres checkpointer
    # Database
    "sqlalchemy>=2.0.40",
    "psycopg2-binary>=2.9.10",
    # Vector store & embeddings
    "qdrant-client>=1.9.0",
    "fastembed>=0.4.0",
    "sentence-transformers>=3.4.0", # For cross-encoder reranking
    # Object storage
    "minio>=7.2.0",
    # Document parsing (default: Docling)
    "docling>=2.15.0",
    # Optional parsers installed via extras: mistral, unstructured
    # Task queue
    "celery>=5.4.0",
    "redis>=5.2.0",
    # Utilities
    "pydantic>=2.10.0",
    "pydantic-settings>=2.7.0",
    "python-dotenv>=1.0.1",
    # Observability
    "prometheus_client>=0.21.0",
    "cachetools>=5.5.0",
    "mistralai>=1.10.0",
    "langchain-groq>=1.1.1",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.3.0",
    "pytest-asyncio>=0.25.0",
    "pytest-cov>=6.0.0",
    "ruff>=0.8.0",
    "mypy>=1.15.0",
    "pre-commit>=4.1.0",
]

# Optional: Additional embedding models
ml = [
    "langchain-huggingface>=0.1.2",
]

# Optional: Alternative document parsers (use PARSER_BACKEND env var to select)
mistral = [
    "mistralai>=1.0.0",
]
unstructured = [
    "unstructured[all-docs]>=0.16.0",
]

[project.scripts]
simba = "simba.cli:main"

[project.urls]
Homepage = "https://github.com/GitHamza0206/simba"
Repository = "https://github.com/GitHamza0206/simba"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["simba"]

[tool.ruff]
line-length = 100
target-version = "py311"

[tool.ruff.lint]
select = ["E", "F", "I", "N", "W", "UP"]
ignore = ["E501"]

[tool.ruff.lint.isort]
known-first-party = ["simba"]

[tool.mypy]
python_version = "3.11"
strict = true
ignore_missing_imports = true

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["tests"]

[tool.uv]
# Use CPU-only PyTorch to reduce Docker image size by ~4GB
# This avoids pulling NVIDIA CUDA libraries in containerized environments

[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

[tool.uv.sources]
torch = { index = "pytorch-cpu" }
torchvision = { index = "pytorch-cpu" }
torchaudio = { index = "pytorch-cpu" }

[dependency-groups]
dev = [
    "pre-commit>=4.5.1",
    "ruff>=0.14.10",
]
